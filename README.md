# VISION

An IOS application that assists the visually impaired in locating common objects around the environment. 

The user can tap on the screen to click a picture, and using machine learning the image is analyzed through our built API to recognize these objects and transcribes them to speech. 



# Built With

- Swift
- Python
- YOLOv3



# TODO

- Include Other OS support (Android)
- Optimize Code


# Authors

- Tamer Algarmakany










        

 
 
 
 
 
        
